<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>(Python Script) Predicting Diabetes Using Tree-based Methods | Hyunjin Nam</title>
    <meta name="description" content="Creative Agency">
    <link rel="icon" href="favicon-32x32.png">
    
    <link rel="preload" href="/assets/css/0.styles.ed98569d.css" as="style"><link rel="preload" href="/assets/js/app.b5f14964.js" as="script"><link rel="preload" href="/assets/js/4.c4f34d79.js" as="script"><link rel="preload" href="/assets/js/8.6efc4c10.js" as="script"><link rel="preload" href="/assets/js/13.815d0c10.js" as="script"><link rel="preload" href="/assets/js/5.c1758e3d.js" as="script"><link rel="prefetch" href="/assets/js/10.f56f931b.js"><link rel="prefetch" href="/assets/js/11.ed1b01bd.js"><link rel="prefetch" href="/assets/js/12.89dc2199.js"><link rel="prefetch" href="/assets/js/14.3fa18dac.js"><link rel="prefetch" href="/assets/js/15.74d7d1ad.js"><link rel="prefetch" href="/assets/js/16.eb153d7e.js"><link rel="prefetch" href="/assets/js/17.82815eee.js"><link rel="prefetch" href="/assets/js/18.e052e3f7.js"><link rel="prefetch" href="/assets/js/19.eaf54ace.js"><link rel="prefetch" href="/assets/js/2.9b5f0a36.js"><link rel="prefetch" href="/assets/js/20.1363daba.js"><link rel="prefetch" href="/assets/js/3.47975e56.js"><link rel="prefetch" href="/assets/js/6.212280d4.js"><link rel="prefetch" href="/assets/js/7.669b2252.js"><link rel="prefetch" href="/assets/js/9.c97ca2d1.js">
    <link rel="stylesheet" href="/assets/css/0.styles.ed98569d.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="wrapper"><header class="header" data-v-03166bf1><nav class="navigation left desktop-nav" data-v-03166bf1><ul data-v-03166bf1><li data-v-03166bf1>Works</li><li data-v-03166bf1>Journal</li><!----><!----><!----> <!----><!----><!----><!----><!----></ul></nav> <div class="brand" data-v-03166bf1><a href="/" class="router-link-active" data-v-03166bf1><div title="Hyunjin Nam" class="logo" style="background-image:url(/upload/logo.svg);" data-v-03166bf1></div></a></div> <nav class="navigation right desktop-nav" data-v-03166bf1><ul data-v-03166bf1><!----><!----><!----><!----><!----> <!----><!----><li data-v-03166bf1><a href="https://www.instagram.com/hyunjinnam0.0" target="_blank" data-v-03166bf1>Instagram</a></li><li data-v-03166bf1><a href="https://www.linkedin.com/in/hyunjin-nam-5bb44a152/" target="_blank" data-v-03166bf1>LinkedIn</a></li><li data-v-03166bf1><a href="mailto:jinanam0116@gmail.com" target="_blank" data-v-03166bf1>Say hi!</a></li></ul></nav> <div class="mobile-nav-toggle" data-v-03166bf1></div> <div class="mobile-nav" data-v-03166bf1><nav data-v-03166bf1><ul data-v-03166bf1><li data-v-03166bf1>Works</li><li data-v-03166bf1>Journal</li><!----><!----><!----> <!----><!----><li data-v-03166bf1><a href="https://www.instagram.com/hyunjinnam0.0" target="_blank" data-v-03166bf1>Instagram</a></li><li data-v-03166bf1><a href="https://www.linkedin.com/in/hyunjin-nam-5bb44a152/" target="_blank" data-v-03166bf1>LinkedIn</a></li><li data-v-03166bf1><a href="mailto:jinanam0116@gmail.com" target="_blank" data-v-03166bf1>Say hi!</a></li></ul> <div class="mobile-nav-close" data-v-03166bf1></div></nav></div></header> <div class="container"><!----> <!----> <!----> <div class="single-journal"><div class="content__default"><h2 id="introduction">Introduction</h2> <p>The aim of this document is to develop a statistical model to predict type 2 diabetes based on the machine learning algorithm, and to check if the statistical approach with patients’ data can detect diabetes correctly. The methodology that will be mainly used will be the tree-based model, which is one of the most frequently used methods in the medical field. It is easy to interpret, mirrors physician’s criteria and gives relatively high accuracy than any other statistical methods. A decision tree is the base-line for the tree-based model, and the two other methods will be modifications of this algorithm. Random forest and Boosting are called Ensemble methods that combine multiple classifiers (several decision trees) in different ways. A random forest can decrease variance, and boosting can reduce bias.</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> tree
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">import</span> pydotplus
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> re
<span class="token keyword">import</span> matplotlib
<span class="token keyword">from</span> IPython<span class="token punctuation">.</span>display <span class="token keyword">import</span> Image
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>externals<span class="token punctuation">.</span>six <span class="token keyword">import</span> StringIO
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> DecisionTreeClassifier
<span class="token keyword">import</span> pandas_profiling

</code></pre></div><p>First we'll load a data from synthea. In this data set, NA is informative missingness. As the patients do not need unnecessary lab tests, NA means the patients’ lab test. Therefore, all the NA in this paper is replaced with 0. As the NA implies some information, the NA is kept as a distinct number so that classifier can detect the difference between the real values and NA, which is encoded as 0.</p> <p>Also Blood pressure variable is slitted it into two variables which are high blood pressure and low blood pressure.</p> <h2 id="data-importing-and-cleansing">Data importing and cleansing</h2> <div class="language-python extra-class"><pre class="language-python"><code>input_file <span class="token operator">=</span> <span class="token string">&quot;/Users/namhyunjin/PycharmProjects/untitled2/synthea_validate.csv&quot;</span>
df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>input_file<span class="token punctuation">,</span> header <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>
df <span class="token operator">=</span> df<span class="token punctuation">.</span>fillna<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token comment">#df=df.fillna(df.mean())</span>


<span class="token comment"># Blood_Pressure</span>
low_blood <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
high_blood <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> row <span class="token keyword">in</span> df<span class="token punctuation">[</span><span class="token string">'Blood_Pressure'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> row <span class="token operator">!=</span><span class="token number">0</span><span class="token punctuation">:</span>
        high_blood<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">float</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>findall<span class="token punctuation">(</span><span class="token string">'\d+'</span><span class="token punctuation">,</span> row<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        low_blood<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">float</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>findall<span class="token punctuation">(</span><span class="token string">'\d+'</span><span class="token punctuation">,</span> row<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        high_blood<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        low_blood<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
df<span class="token punctuation">[</span><span class="token string">'low_blood'</span><span class="token punctuation">]</span> <span class="token operator">=</span> low_blood
df<span class="token punctuation">[</span><span class="token string">'high_blood'</span><span class="token punctuation">]</span> <span class="token operator">=</span> high_blood
</code></pre></div><p>Define diabetes as a patients who has a 'Condition' variable recoreded as 'Diabetes' and 'Prediabetes'. Drop the variables that are irrelevent to data analysis. Also rename the variable so that XGBoost can understand the variables(XGBoost algorithm does not allow variables to have '[',']', and '&lt;' for their names)</p> <div class="language-python extra-class"><pre class="language-python"><code>df<span class="token punctuation">[</span><span class="token string">'diabetes'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">.</span>Condition<span class="token punctuation">.</span>isin<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'Diabetes'</span><span class="token punctuation">,</span> <span class="token string">'Prediabetes'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
df <span class="token operator">=</span> df<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'Condition'</span><span class="token punctuation">,</span><span class="token string">'Blood_Pressure'</span><span class="token punctuation">,</span><span class="token string">'Unnamed: 0'</span><span class="token punctuation">,</span> <span class="token string">'Patient_Year'</span><span class="token punctuation">,</span><span class="token string">'Immunization'</span><span class="token punctuation">,</span><span class="token string">'Diagnostic_Report'</span><span class="token punctuation">,</span>
              <span class="token string">'Procedure'</span><span class="token punctuation">,</span> <span class="token string">'Condition'</span><span class="token punctuation">,</span><span class="token string">'Care_Plan'</span><span class="token punctuation">,</span> <span class="token string">'Quality adjusted life years'</span><span class="token punctuation">,</span> <span class="token string">'Disability rating scale'</span><span class="token punctuation">,</span>
              <span class="token string">'Housing status'</span><span class="token punctuation">,</span> <span class="token string">'Are you covered by health insurance or some other kind of health care plan [PhenX]'</span><span class="token punctuation">,</span>
              <span class="token string">'Total score [MMSE]'</span><span class="token punctuation">,</span><span class="token string">'Medication'</span><span class="token punctuation">,</span> <span class="token string">'Encounter'</span><span class="token punctuation">,</span><span class="token string">'Allergy_Intolerance'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token comment"># rename variables</span>
regex <span class="token operator">=</span> re<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span><span class="token string">r&quot;\[|\]|&lt;&quot;</span><span class="token punctuation">,</span> re<span class="token punctuation">.</span>IGNORECASE<span class="token punctuation">)</span>
a <span class="token operator">=</span> <span class="token punctuation">[</span>regex<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">&quot;_&quot;</span><span class="token punctuation">,</span> col<span class="token punctuation">)</span> <span class="token keyword">if</span> <span class="token builtin">any</span><span class="token punctuation">(</span>x <span class="token keyword">in</span> <span class="token builtin">str</span><span class="token punctuation">(</span>col<span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token builtin">set</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'['</span><span class="token punctuation">,</span> <span class="token string">']'</span><span class="token punctuation">,</span> <span class="token string">'&lt;'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">else</span> col <span class="token keyword">for</span> col <span class="token keyword">in</span> df<span class="token punctuation">.</span>columns<span class="token punctuation">.</span>values<span class="token punctuation">]</span>
df<span class="token punctuation">.</span>columns <span class="token operator">=</span> a

<span class="token comment"># clean the data</span>
d_tf <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token boolean">True</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">:</span><span class="token number">0</span><span class="token punctuation">}</span>
df<span class="token punctuation">[</span><span class="token string">'diabetes'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'diabetes'</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>d_tf<span class="token punctuation">)</span>
</code></pre></div><p>Before going into the analysis process, a dataset can be divided into training and testing data. Most of the data is used for training, and a smaller amount of the data is used for testing. Training data is used to fit a parameter and builds the models to find an algorithm to map the function where X is an input vector, and Y is an output vector. In this study, the output vector is the diagnosis of diabetes and f(X) is the decision tree, random forest, and boosting</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># Devide data</span>
features <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">49</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'diabetes'</span><span class="token punctuation">]</span>
X <span class="token operator">=</span> df<span class="token punctuation">[</span>features<span class="token punctuation">]</span>
X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="data-description">Data description</h2> <p>There are 50 variables in the data set. The variables are information about paitent's health such as &quot;Body height&quot;, &quot;Calcium&quot;, &quot;Carbon Diaxide&quot;, and so on. As we inputted 0 for missing valuses, there are a lot of 0 in the whole dataset. Some of the variables are highly correlated. For example, &quot;Body Weight&quot; and &quot;Body Mass Index&quot; are highly correlated, and &quot;Creatinine&quot; and &quot;Chloride&quot; are highly correlated.</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">print</span><span class="token punctuation">(</span>pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span> index <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;Diabetes&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;Not Diabetes&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                   data <span class="token operator">=</span> <span class="token punctuation">[</span>df<span class="token punctuation">.</span>diabetes<span class="token punctuation">.</span>value_counts<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>df<span class="token punctuation">.</span>diabetes<span class="token punctuation">.</span>value_counts<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                  columns <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;Number of patiens&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><pre><code>              Number of patiens
Diabetes                  13410
Not Diabetes                522
</code></pre> <p>The output variables is the patient's condition if they have diabetes or not. Among 13932 patients, there are 522 patinets who are having a diabetes and 13410 patients who does not have diabetes.</p> <h1 id="decision-tree">Decision Tree</h1> <p>A decision tree is a machine learning methods that is useful for interpretation. It can be displayed graphically and is easily understood even by a non-expert. It also mirrors a physician’s criteria to diagnosis diseases. It uses a greedy approach for recursive binary splitting; at each step of the tree-building process, the best split is chosen at that particular step, rather than looking ahead and picking a split that will lead to a better tree in some future step. Therefore, patients can go through laboratory test according to the sequence of the nodes and can terminate sooner if they meet certain conditions. Unfortunately, a simple decision tree may not perform as well as other Machine Learning algorithms. However, many decision trees using ensemble methods (random forests and boosting); this limitation can be redeemed and provide high prediction accuracy.</p> <div class="language-python extra-class"><pre class="language-python"><code>tree_clf <span class="token operator">=</span> tree<span class="token punctuation">.</span>DecisionTreeClassifier<span class="token punctuation">(</span>criterion <span class="token operator">=</span> <span class="token string">&quot;gini&quot;</span><span class="token punctuation">,</span> splitter <span class="token operator">=</span> <span class="token string">'random'</span><span class="token punctuation">,</span> max_leaf_nodes <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">,</span> min_samples_leaf <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span> max_depth<span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span>
tree_clf <span class="token operator">=</span> tree_clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>
</code></pre></div><p>First of all, to make the model simple and easy to interpret, I set the hyperparameter like as above. It will create some restriction to tree model and make model not grow too deeply. Maximum numver of leaf nodes is 5, minimum number of samples leaf is 5, and maximum depth for the tree is 5.</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># Visualize</span>
dot_data <span class="token operator">=</span> StringIO<span class="token punctuation">(</span><span class="token punctuation">)</span>
tree<span class="token punctuation">.</span>export_graphviz<span class="token punctuation">(</span>tree_clf<span class="token punctuation">,</span> out_file<span class="token operator">=</span>dot_data<span class="token punctuation">,</span> feature_names<span class="token operator">=</span>features<span class="token punctuation">)</span>
graph <span class="token operator">=</span> pydotplus<span class="token punctuation">.</span>graph_from_dot_data<span class="token punctuation">(</span>dot_data<span class="token punctuation">.</span>getvalue<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
Image<span class="token punctuation">(</span>graph<span class="token punctuation">.</span>create_png<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>Figure above shows the result for the decision tree. A node, which is divided into sub-nodes, is named a parent node of sub-nodes where a sub-nodes are the child of the parent node. For in this case, There are 9 nodes included roots nodes, which is Glucoes. In theLeft split of the root node, &quot;Death&quot; is root nodes for this sub-trees and &quot;Oral temperature&quot; is the sub-nodes. The tree’s root node can be interpreted like &quot;Is the low blood pressure level under 29.24?&quot;. If the patients have under 29.24 glucose level, then it should follow the left-node.</p> <div class="language-python extra-class"><pre class="language-python"><code>tree_imp <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">'Var'</span> <span class="token punctuation">:</span> X_train<span class="token punctuation">.</span>columns<span class="token punctuation">,</span><span class="token string">'Imp'</span> <span class="token punctuation">:</span> tree_clf<span class="token punctuation">.</span>feature_importances_ <span class="token punctuation">}</span><span class="token punctuation">)</span>
tree_imp <span class="token operator">=</span> tree_imp<span class="token punctuation">.</span>sort_values<span class="token punctuation">(</span>by <span class="token operator">=</span> <span class="token string">'Imp'</span><span class="token punctuation">,</span> ascending<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span>
tree_imp<span class="token punctuation">.</span>plot<span class="token punctuation">.</span>bar<span class="token punctuation">(</span>x<span class="token operator">=</span><span class="token string">'Var'</span><span class="token punctuation">,</span> y<span class="token operator">=</span><span class="token string">'Imp'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><p><img src="" alt="png"></p> <p>Figure aboe shows the relative importance for the variables. A measure of variable importance is the sum of Gini impurity index for each split for which it means it shows the most important variable that is used to predict diabetes. It shows that 'low blood pressure', 'Total Cholesterol' and 'Death' are the 3 most important factors.</p> <div class="language-python extra-class"><pre class="language-python"><code>tree_y_pred <span class="token operator">=</span> tree_clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> metrics
<span class="token keyword">print</span><span class="token punctuation">(</span>pd<span class="token punctuation">.</span>crosstab<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> tree_y_pred<span class="token punctuation">,</span> rownames <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'y_test'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> colnames <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'tree_y_pred'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Accuracy:&quot;</span><span class="token punctuation">,</span>metrics<span class="token punctuation">.</span>accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> tree_y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><pre><code>tree_y_pred     0
y_test           
0            4022
1             158
Accuracy: 0.9622009569377991
</code></pre> <p>The test data prediction accuracy is 96.268%. Therefore, we can conclude that decision tree can be a propriate method to predict diabetes.</p> <h1 id="random-forest">Random Forest</h1> <p>Random forests is an ensemble machine learning method. It is well known as a strong predictor that can be also easy to interpret. Random forests is a substantial modification technique of bagging that builds a B number of de-correlated sample trees. Bagging is an ensemble learning method which is the shortened term for’ bootstrap aggregating’. It involves bootstrapping the train data into B different set, and for iteration, it is building different decision trees. Aggregating gives an output of the class that earned the most votes of the B number of trees. Since bagging is aggregating a number of trees, it can reduce variance and helps to avoid over-fitting. Whenever split is decided in bagging, like as the decision tree, every variable is on the consideration, even though it is using a bootstrapped sample, there is a high chance that all of the bagged trees might look similar to each other. In other words, the bagged trees will be highly correlated and averaging many highly correlated quantities does not lead to better performance.</p> <p>Random forest builds a B number of decision trees on bootstrapped training samples, which is the same procedure with bagging. However, in Random forest model, when each split is made, a random sample of m (= square of p) predictors is chosen instead of using the full set of p predictors. Hence, Random forest can give a reduction in variance as averaging many uncorrelated quantitie.</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> RandomForestClassifier
rf_clf <span class="token operator">=</span> RandomForestClassifier<span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">)</span>
rf_clf <span class="token operator">=</span> rf_clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>
</code></pre></div><p>I set the number of trees as 300.</p> <div class="language-python extra-class"><pre class="language-python"><code>rf_feature_imp <span class="token operator">=</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span>rf_clf<span class="token punctuation">.</span>feature_importances_<span class="token punctuation">,</span>index<span class="token operator">=</span>X_train<span class="token punctuation">.</span>columns<span class="token punctuation">)</span><span class="token punctuation">.</span>sort_values<span class="token punctuation">(</span>ascending<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span>
rf_feature_imp<span class="token punctuation">.</span>plot<span class="token punctuation">.</span>bar<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><p><img src="/upload/notebook1/output_29_0.png" alt="png"></p> <p>Figure above shows the relative importance for the variables. Random forest shows &quot;Body Height&quot;, &quot;Body Mass Index&quot;,&quot;Low Blood pressure&quot; as an important variables.</p> <div class="language-python extra-class"><pre class="language-python"><code>rf_y_pred <span class="token operator">=</span> rf_clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>pd<span class="token punctuation">.</span>crosstab<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> rf_y_pred<span class="token punctuation">,</span> rownames <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'y_test'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> colnames <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'rf_y_pred'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Accuracy:&quot;</span><span class="token punctuation">,</span>metrics<span class="token punctuation">.</span>accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> rf_y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><pre><code>rf_y_pred     0
y_test         
0          4022
1           158
Accuracy: 0.9622009569377991
</code></pre> <p>The test data prediction accuracy is 96.22%. It is showing a strong performance, but showing less accuracy then decision tree.</p> <h1 id="xgboost">XGBoost</h1> <p>Boosting is an ensemble technique that new models are added to fix the errors made by existing models. Models are added recursively till no noticeable improvements can be detected. Each tree in boosting has high bias, but by effectively combining these weak trees, it will produce a low bias and low variance result. In contrast to Random Forest, it will grow simpler trees with fewer splits.</p> <p>XGBoost is an implementation technique of gradient boosting machines created by Tianqi Chen. The difference in modelling details is that Xgboost used a more regularised model formalisation to control over-fitting, which gives it better performance. The XGBoost algorithm combines many week classifiers, and by combining them, it gets better performance. Each tree has a high bias with weak performance. It starts by building an initial tree with high bias, which has a poor performance by itself. Then it sequentially builds next tree which is trained to predict what the previous tree was not able to fitted well and is itself a weak learner too. It continues this procedure until stopping criteria met. XGBoost is providing the advantages of higher execution speeds, better model performance, enabling parallelised computations, cache optimisation, and out-of-core computing for huge databases.</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> xgboost <span class="token keyword">as</span> xgb
<span class="token keyword">from</span> xgboost <span class="token keyword">import</span> XGBClassifier
<span class="token keyword">from</span> xgboost<span class="token punctuation">.</span>sklearn <span class="token keyword">import</span> XGBClassifier
<span class="token keyword">from</span> xgboost <span class="token keyword">import</span> plot_importance

dtrain <span class="token operator">=</span> xgb<span class="token punctuation">.</span>DMatrix<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> label<span class="token operator">=</span> y_train<span class="token punctuation">)</span>
dtest <span class="token operator">=</span> xgb<span class="token punctuation">.</span>DMatrix<span class="token punctuation">(</span>X_test<span class="token punctuation">,</span> label<span class="token operator">=</span> y_test<span class="token punctuation">)</span>

param <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token string">'eta'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'objective'</span><span class="token punctuation">:</span> <span class="token string">'binary:logistic'</span><span class="token punctuation">}</span>
num_round <span class="token operator">=</span> <span class="token number">40</span>
evallist <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>dtest<span class="token punctuation">,</span> <span class="token string">'eval'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>dtrain<span class="token punctuation">,</span> <span class="token string">'train'</span><span class="token punctuation">)</span><span class="token punctuation">]</span>

bst <span class="token operator">=</span> xgb<span class="token punctuation">.</span>train<span class="token punctuation">(</span>param<span class="token punctuation">,</span> dtrain<span class="token punctuation">,</span> num_round<span class="token punctuation">,</span> evallist<span class="token punctuation">)</span>
</code></pre></div><pre><code>[0]	eval-error:0.037799	train-error:0.037326
[5]	eval-error:0.03756	train-error:0.036505
[10]	eval-error:0.038278	train-error:0.033942
[15]	eval-error:0.038278	train-error:0.033121
[20]	eval-error:0.038278	train-error:0.033019
[25]	eval-error:0.038517	train-error:0.033019
[30]	eval-error:0.038517	train-error:0.033019
[35]	eval-error:0.038278	train-error:0.033019
[40]	eval-error:0.038278	train-error:0.033019
</code></pre> <p>First of all, to make the model simple and easy to interpret, I set the hyperparameter like as above. It will create some restriction to boosting model and prevent overfit. Maximum depth for the tree is 5, and lower learning rate $eta$ is 1, and number of iteration is 50.</p> <div class="language-python extra-class"><pre class="language-python"><code>xgb<span class="token punctuation">.</span>plot_importance<span class="token punctuation">(</span>bst<span class="token punctuation">,</span> max_num_features<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><p><img src="/upload/notebook1/output_37_0.png" alt="png"></p> <p>Figure above shows the relative importance for the variables. Random forest shows &quot;Body Weight&quot;, &quot;Body Height&quot; , &quot;Low High pressure&quot; as an important variables.</p> <div class="language-python extra-class"><pre class="language-python"><code>xg_y_pred <span class="token operator">=</span> bst<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>dtest<span class="token punctuation">)</span>
xg_y_pred  <span class="token operator">=</span> xg_y_pred <span class="token operator">&gt;</span> <span class="token number">0.5</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>pd<span class="token punctuation">.</span>crosstab<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> xg_y_pred<span class="token punctuation">,</span> rownames <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'y_test'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> colnames <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'xg_y_pred'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Accuracy:&quot;</span><span class="token punctuation">,</span>metrics<span class="token punctuation">.</span>accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> xg_y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><pre><code>xg_y_pred  False  True 
y_test                 
0           4019      3
1            158      0
Accuracy: 0.9614832535885167
</code></pre> <p>The test data prediction accuracy is 96.17%. It is showing a strong performance, but showing less accuracy than decision tree and randomforest.</p> <div class="language-python extra-class"><pre class="language-python"><code>
</code></pre></div></div></div></div> <span class="text" data-v-5f413788>Hyunjin Nam</span></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.b5f14964.js" defer></script><script src="/assets/js/4.c4f34d79.js" defer></script><script src="/assets/js/8.6efc4c10.js" defer></script><script src="/assets/js/13.815d0c10.js" defer></script><script src="/assets/js/5.c1758e3d.js" defer></script>
  </body>
</html>
